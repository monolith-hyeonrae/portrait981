"""Face classifier extractor - classifies detected faces by role.

Depends on face_detect to classify faces as:
- main: Primary subject (driver/main person)
- passenger: Secondary subject (co-passenger)
- transient: Temporarily detected face (passing by)
- noise: False detection or low-quality face
"""

from dataclasses import dataclass, field
from typing import Optional, Dict, List
from collections import defaultdict
import logging
import time

from visualbase import Frame

from facemoment.moment_detector.extractors.base import (
    Module,
    Observation,
    FaceObservation,
    ProcessingStep,
    processing_step,
    get_processing_steps,
)
from facemoment.moment_detector.extractors.outputs import FaceDetectOutput

logger = logging.getLogger(__name__)


@dataclass
class ClassifiedFace:
    """Face with classification info."""
    face: FaceObservation
    role: str  # "main", "passenger", "transient", "noise"
    confidence: float  # Classification confidence
    track_length: int  # Number of consecutive frames tracked
    avg_area: float  # Average area ratio over track


@dataclass
class FaceClassifierOutput:
    """Output from FaceClassifierExtractor."""
    faces: List[ClassifiedFace] = field(default_factory=list)
    main_face: Optional[ClassifiedFace] = None
    passenger_faces: List[ClassifiedFace] = field(default_factory=list)
    transient_count: int = 0
    noise_count: int = 0


class FaceClassifierExtractor(Module):
    """Classifies detected faces by their role in the scene.

    Uses temporal tracking and spatial analysis to classify faces:
    - main: Largest, most central, consistently present
    - passenger: Secondary position, consistently present
    - transient: Appears for only a few frames
    - noise: Too small, edge of frame, or low confidence

    depends: ["face_detect"]

    Args:
        min_track_frames: Minimum frames to be considered non-transient (default: 5)
        min_area_ratio: Minimum face area ratio to not be noise (default: 0.005)
        min_confidence: Minimum detection confidence (default: 0.5)
        main_zone: Normalized x-range for main subject (default: (0.3, 0.7))
        edge_margin: Margin from edge to be considered valid (default: 0.05)

    Example:
        >>> classifier = FaceClassifierExtractor()
        >>> # Use with FlowGraph
        >>> graph = (FlowGraphBuilder()
        ...     .source()
        ...     .path("detect", modules=[FaceDetectionExtractor()])
        ...     .path("classify", modules=[FaceClassifierExtractor()])
        ...     .build())
    """

    depends = ["face_detect"]

    def __init__(
        self,
        min_track_frames: int = 5,
        min_area_ratio: float = 0.005,
        min_confidence: float = 0.3,
        main_zone: tuple[float, float] = (0.3, 0.7),
        edge_margin: float = 0.05,
    ):
        self._min_track_frames = min_track_frames
        self._min_area_ratio = min_area_ratio
        self._min_confidence = min_confidence
        self._main_zone = main_zone
        self._edge_margin = edge_margin

        # Tracking state: face_id -> history
        self._track_history: Dict[int, List[FaceObservation]] = defaultdict(list)
        self._track_stats: Dict[int, Dict] = {}

        # Step timing tracking (auto-populated by @processing_step decorator)
        self._step_timings: Optional[Dict[str, float]] = None

    @property
    def name(self) -> str:
        return "face_classifier"

    @property
    def processing_steps(self) -> List[ProcessingStep]:
        """Get the list of internal processing steps (auto-extracted from decorators)."""
        return get_processing_steps(self)

    def initialize(self) -> None:
        self._track_history.clear()
        self._track_stats.clear()
        logger.info("FaceClassifierExtractor initialized")

    def cleanup(self) -> None:
        self._track_history.clear()
        self._track_stats.clear()
        logger.info("FaceClassifierExtractor cleaned up")

    # ========== Processing Steps (decorated methods) ==========

    @processing_step(
        name="track_update",
        description="Update face tracking history and stats",
        input_type="List[FaceObservation]",
        output_type="Set[int] (current IDs)",
    )
    def _update_tracking(self, faces: List[FaceObservation]) -> set:
        """Update tracking history for all faces."""
        current_ids = set()
        for face in faces:
            self._track_history[face.face_id].append(face)
            current_ids.add(face.face_id)
            self._update_stats(face.face_id, face)
        return current_ids

    @processing_step(
        name="classify",
        description="Classify each face (noise, transient, main/passenger candidate)",
        backend="Rule-based scorer",
        input_type="List[FaceObservation]",
        output_type="List[ClassifiedFace]",
        depends_on=["track_update"],
    )
    def _classify_faces(self, faces: List[FaceObservation]) -> List[ClassifiedFace]:
        """Classify each face based on criteria."""
        classified_faces = []
        for face in faces:
            role, confidence = self._classify_face(face)
            track_length = len(self._track_history[face.face_id])
            avg_area = self._track_stats[face.face_id].get("avg_area", face.area_ratio)

            classified = ClassifiedFace(
                face=face,
                role=role,
                confidence=confidence,
                track_length=track_length,
                avg_area=avg_area,
            )
            classified_faces.append(classified)
        return classified_faces

    @processing_step(
        name="role_assignment",
        description="Assign unique roles (1 main, <=1 passenger)",
        input_type="List[ClassifiedFace]",
        output_type="FaceClassifierOutput",
        depends_on=["classify"],
    )
    def _assign_roles(self, classified_faces: List[ClassifiedFace]) -> Dict:
        """Assign unique roles ensuring 1 main and at most 1 passenger."""
        candidates = []
        transient_faces = []
        noise_faces = []

        for cf in classified_faces:
            if cf.role in ("main", "passenger"):
                score = cf.avg_area * 100 + cf.track_length * 0.1
                candidates.append((score, cf))
            elif cf.role == "transient":
                transient_faces.append(cf)
            else:
                noise_faces.append(cf)

        candidates.sort(key=lambda x: x[0], reverse=True)

        main_face = None
        passenger_faces = []
        demoted_to_transient = []

        if candidates:
            best = candidates[0][1]
            main_face = ClassifiedFace(
                face=best.face,
                role="main",
                confidence=best.confidence,
                track_length=best.track_length,
                avg_area=best.avg_area,
            )

            if len(candidates) > 1:
                second = candidates[1][1]
                passenger = ClassifiedFace(
                    face=second.face,
                    role="passenger",
                    confidence=second.confidence,
                    track_length=second.track_length,
                    avg_area=second.avg_area,
                )
                passenger_faces = [passenger]

            for _, cf in candidates[2:]:
                demoted_to_transient.append(ClassifiedFace(
                    face=cf.face,
                    role="transient",
                    confidence=cf.confidence,
                    track_length=cf.track_length,
                    avg_area=cf.avg_area,
                ))

        final_faces = []
        if main_face:
            final_faces.append(main_face)
        final_faces.extend(passenger_faces)
        final_faces.extend(demoted_to_transient)
        final_faces.extend(transient_faces)
        final_faces.extend(noise_faces)

        return {
            "faces": final_faces,
            "main_face": main_face,
            "passenger_faces": passenger_faces,
            "transient_count": len(transient_faces) + len(demoted_to_transient),
            "noise_count": len(noise_faces),
        }

    # ========== Main process method ==========

    def process(
        self,
        frame: Frame,
        deps: Optional[Dict[str, Observation]] = None,
    ) -> Optional[Observation]:
        # Support both face_detect (split) and face (composite) extractors
        face_obs = None
        faces = []

        if deps:
            if "face_detect" in deps:
                face_obs = deps["face_detect"]
                if face_obs.data and hasattr(face_obs.data, 'faces'):
                    faces = face_obs.data.faces
            elif "face" in deps:
                face_obs = deps["face"]
                faces = face_obs.faces if face_obs.faces else []

        if face_obs is None:
            logger.warning("FaceClassifierExtractor: no face_detect or face dependency")
            return None

        if not faces:
            return Observation(
                source=self.name,
                frame_id=frame.frame_id,
                t_ns=frame.t_src_ns,
                signals={
                    "main_detected": 0,
                    "passenger_count": 0,
                    "transient_count": 0,
                    "noise_count": 0,
                },
                data=FaceClassifierOutput(),
            )

        # Enable step timing collection
        self._step_timings = {}

        # Execute processing steps (timing auto-tracked by decorators)
        current_ids = self._update_tracking(faces)
        classified_faces = self._classify_faces(faces)
        result = self._assign_roles(classified_faces)

        # Clean up old tracks
        self._cleanup_old_tracks(current_ids)

        # Collect timing data
        timing = self._step_timings.copy() if self._step_timings else None
        self._step_timings = None

        return Observation(
            source=self.name,
            frame_id=frame.frame_id,
            t_ns=frame.t_src_ns,
            signals={
                "main_detected": 1 if result["main_face"] else 0,
                "passenger_count": len(result["passenger_faces"]),
                "transient_count": result["transient_count"],
                "noise_count": result["noise_count"],
                "total_faces": len(result["faces"]),
            },
            data=FaceClassifierOutput(
                faces=result["faces"],
                main_face=result["main_face"],
                passenger_faces=result["passenger_faces"],
                transient_count=result["transient_count"],
                noise_count=result["noise_count"],
            ),
            timing=timing,
        )

    # ========== Helper methods (not processing steps) ==========

    def _classify_face(self, face: FaceObservation) -> tuple[str, float]:
        """Classify a face based on various criteria."""
        track_length = len(self._track_history[face.face_id])
        stats = self._track_stats.get(face.face_id, {})

        if self._is_noise(face, stats):
            return ("noise", 0.9)

        if track_length < self._min_track_frames:
            return ("transient", 0.7)

        center_x = face.bbox[0] + face.bbox[2] / 2
        main_zone_left, main_zone_right = self._main_zone

        main_score = 0.0
        position_stability = stats.get("position_stability", 0.5)
        max_drift = stats.get("max_position_drift", 0.0)

        if max_drift > 0.15:
            return ("transient", 0.8)

        main_score += position_stability * 0.4

        avg_area = stats.get("avg_area", face.area_ratio)
        if avg_area > 0.05:
            main_score += 0.3
        elif avg_area > 0.02:
            main_score += 0.2
        else:
            main_score += 0.1

        if main_zone_left <= center_x <= main_zone_right:
            main_score += 0.2
        else:
            main_score += 0.05

        if face.inside_frame:
            main_score += 0.1

        if main_score >= 0.5 and position_stability >= 0.5:
            return ("main", main_score)
        elif main_score >= 0.3 and position_stability >= 0.3:
            return ("passenger", main_score)
        else:
            return ("transient", main_score)

    def _is_noise(self, face: FaceObservation, stats: Dict) -> bool:
        """Check if face is likely noise/false detection."""
        if face.area_ratio < self._min_area_ratio:
            return True
        if face.confidence < self._min_confidence:
            return True

        x, y, w, h = face.bbox
        is_cut_off = (x < 0.01 or y < 0.01 or x + w > 0.99 or y + h > 0.99)
        if is_cut_off and face.area_ratio < 0.008:
            return True

        return False

    def _update_stats(self, face_id: int, face: FaceObservation) -> None:
        """Update aggregated stats for a face track."""
        center_x = face.bbox[0] + face.bbox[2] / 2
        center_y = face.bbox[1] + face.bbox[3] / 2

        if face_id not in self._track_stats:
            self._track_stats[face_id] = {
                "avg_area": face.area_ratio,
                "avg_center_x": center_x,
                "avg_center_y": center_y,
                "position_stability": 1.0,
                "max_position_drift": 0.0,
                "frame_count": 1,
            }
        else:
            stats = self._track_stats[face_id]
            alpha = 0.3
            stats["avg_area"] = (1 - alpha) * stats["avg_area"] + alpha * face.area_ratio

            drift_x = abs(center_x - stats["avg_center_x"])
            drift_y = abs(center_y - stats["avg_center_y"])
            position_drift = (drift_x ** 2 + drift_y ** 2) ** 0.5

            stats["max_position_drift"] = max(stats["max_position_drift"], position_drift)

            alpha_pos = 0.1
            stats["avg_center_x"] = (1 - alpha_pos) * stats["avg_center_x"] + alpha_pos * center_x
            stats["avg_center_y"] = (1 - alpha_pos) * stats["avg_center_y"] + alpha_pos * center_y

            if position_drift > 0.1:
                stats["position_stability"] = max(0, stats["position_stability"] - 0.3)
            elif position_drift > 0.05:
                stats["position_stability"] = max(0, stats["position_stability"] - 0.1)
            else:
                stats["position_stability"] = min(1, stats["position_stability"] + 0.02)

            stats["frame_count"] += 1

    def _cleanup_old_tracks(self, current_ids: set, max_history: int = 30) -> None:
        """Remove old tracks and limit history length."""
        to_remove = []
        for face_id in self._track_history:
            if face_id not in current_ids:
                history = self._track_history[face_id]
                if len(history) > max_history:
                    to_remove.append(face_id)

        for face_id in to_remove:
            del self._track_history[face_id]
            if face_id in self._track_stats:
                del self._track_stats[face_id]

        for face_id in self._track_history:
            if len(self._track_history[face_id]) > max_history:
                self._track_history[face_id] = self._track_history[face_id][-max_history:]
